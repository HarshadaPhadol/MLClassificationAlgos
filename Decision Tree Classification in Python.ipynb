{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Import the necessary libraries.\nimport numpy as np\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics , model_selection\nfrom mlxtend.plotting import plot_confusion_matrix\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix \nfrom sklearn.tree import export_graphviz\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cars_data = pd.read_csv(\"../input/car-evaluation-datacset/car.csv\")\ncars_data=cars_data[[\n    \"buying\",\n    \"maint\",\n    \"doors\",\n    \"persons\",\n    \"lug_boot\",\n    \"safety\",\n    \"class\"\n]].dropna(axis=0, how='any')\ncars_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#The target variable is marked as class in the dataframe. \n#The values are present in string format.We can convert the string nominal values into numerics values using factorize method of the pandas library.\ncars_data['class'],class_names = pd.factorize(cars_data['class'])\ncars_data['buying'],_ = pd.factorize(cars_data['buying'])\ncars_data['maint'],_ = pd.factorize(cars_data['maint'])\ncars_data['doors'],_ = pd.factorize(cars_data['doors'])\ncars_data['persons'],_ = pd.factorize(cars_data['persons'])\ncars_data['lug_boot'],_ = pd.factorize(cars_data['lug_boot'])\ncars_data['safety'],_ = pd.factorize(cars_data['safety'])\ncars_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Select the feature and target variable\n#X = cars_data.iloc[:,:-1]\n#y = cars_data.iloc[:,-1]\nX = cars_data[cars_data.columns[: -1]]\ny = cars_data['class']\n\n#To split data (e.g. test=200)\n#X_train200, X_test200, y_train200, y_test200 = model_selection.train_test_split(X, y, test_size=0.08)\n\n#To split data in order (e.g. First 1589 records Train= 1589 Test=139)\nX_train, X_test200, y_train, y_test200 = model_selection.train_test_split(X, y, test_size=0.08)\n\n\n#To split data in order (e.g. First 1261 records)\n#train_pct_index = int(0.73 * len(X))\n#X_train, X_test = X[:train_pct_index], X[train_pct_index:]\n#y_train, y_test = y[:train_pct_index], y[train_pct_index:]\n\n#To split data in order (e.g. First 760 records)\n#train_pct_index = int(0.44 * len(X))\n#X_train, X_test = X[:train_pct_index], X[train_pct_index:]\n#y_train, y_test = y[:train_pct_index], y[train_pct_index:]\n\n#To split data in order (e.g. First 501 records)\n#train_pct_index = int(0.29 * len(X))\n#X_train, X_test = X[:train_pct_index], X[train_pct_index:]\n#y_train, y_test = y[:train_pct_index], y[train_pct_index:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training / model fitting\ntree = DecisionTreeClassifier()\ntree.fit(X_train, y_train)\ny_pred = tree.predict(X_test200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy:\",metrics.accuracy_score(y_test200, y_pred))\ncount_misclassified = (y_test200 != y_pred).sum()\nprint('Misclassified samples: {}'.format(count_misclassified))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(metrics.classification_report(y_test200, y_pred))\nconfusion_mc = pd.DataFrame(\n    confusion_matrix(y_test200, y_pred),\n    columns=['unacc', 'acc', 'vgood',  'good'],\n    index=['unacc', 'acc', 'vgood',  'good']\n)\nprint(confusion_mc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To avoid Zero Devision Warning\n#from sklearn.metrics import f1_score\n#metrics.f1_score(y_test, y_pred,average='weighted', labels=np.unique(y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#class_names = ['unacc', 'acc', 'vgood',  'good']\nconfusion_mc = confusion_matrix(y_test200, y_pred)\nfig, ax = plot_confusion_matrix(conf_mat=confusion_mc,\n                                colorbar=True,\n                                show_absolute=False,\n                                show_normed=True)\nplt.title('Decision Tree \\nAccuracy:{0:.3f}'.format(metrics.accuracy_score(y_test200, y_pred)))\nplt.figure(figsize=(10,8))\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualization of the decision graph \nfeat_names = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety']\ntarg_names = ['unacc', 'acc', 'vgood',  'good']\nexport_graphviz(tree, out_file='tree_limited.dot', feature_names = feat_names,\n                class_names = targ_names,\n                rounded = True, proportion = False, precision = 2, filled = True)\n!dot -Tpng tree_limited.dot -o tree_limited.png -Gdpi=600\nfrom IPython.display import Image\nImage(filename = 'tree_limited.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_mc = confusion_mc.astype('float') / confusion_mc.sum(axis=1)[:, np.newaxis]\nprint(\"Per Class Classification Matrix:\",confusion_mc.diagonal())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.bar(range(4),confusion_mc.diagonal(),color = 'black', align = 'center')\nplt.title(\"Per Class Classification \") \nplt.style.use('ggplot')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}